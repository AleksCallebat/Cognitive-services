{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big><big><big><b>Spoiling movies with text analysis API</b></big></big></big>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, we get scripts of movies, assign each sentence to a character, and give each of those sentences to the text analitics API. The most interesting feature of this API is to give an indicator of sentiment of a sentence, which is an indicator from 0 to 1, reflecting how happy the character is.\n",
    "\n",
    "By doing so, we can get insights about the global situation of each character, and can follow the evolution of some characters through a movie.\n",
    "\n",
    "<b> warning : </b> there will be spoilers.\n",
    "\n",
    "So, let's spoil.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing needed, an API key for a cognitive service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API_KEY=\"0ce77ac4203a40569f40a3a37525ece4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import codecs\n",
    "import urllib.request\n",
    "import io\n",
    "import ast\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then get the script from the internet and clean it a tiny bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url=\"http://www.imsdb.com/scripts/Star-Wars-A-New-Hope.html\"\n",
    "u = urllib.request.urlopen(url, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8')\n",
    "text = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go.\n",
    "\n",
    "In a first time, let's just take the five main characters of the movie : LEIA, LUKE, THREEPIO, VADER, and HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script=text.split(\"scrtext\")[1]\n",
    "script=script.replace(\"\\n\",\"\").split(\"<b>\")\n",
    "\n",
    "characters=[\"THREEPIO\",\"LUKE\",\"VADER\",\"HAN\",\"LEIA\",\"BEN\"]\n",
    "\n",
    "def sort_by_characters(characters,script):\n",
    "    interventions={character:[] for character in characters}\n",
    "    for k in script:\n",
    "        for character in characters:\n",
    "            if character in k:\n",
    "                intervention=k.split(\"</b>\")[1]\n",
    "                for k in range(30):\n",
    "                    intervention=intervention.replace(\"  \",\" \")\n",
    "                for phrase in intervention.split(\".\"):\n",
    "                    if phrase!=\"\":\n",
    "                        interventions[character].append(phrase)\n",
    "                break\n",
    "    return interventions\n",
    "\n",
    "interventions=sort_by_characters(characters,script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in characters:\n",
    "    print(character,\" has \",len(interventions[character]),\" sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see, there are a few minorities which are not given the same amount of attention (aka the women and the guy in black)\n",
    "\n",
    "Let's start analysing those interventions with the sentiment analysis. It's quite demanding : at least 20 lines to do it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do the same for Luke, leia etc\n",
    "def get_data(PERSO,param='sentiment'):\n",
    "    body={\n",
    "      \"documents\": [\n",
    "        {\n",
    "          \"id\": str(k),\n",
    "          \"text\": PERSO[k]\n",
    "        } for k in range(len(PERSO)) if (len(PERSO[k].split(\" \"))>0 and (not PERSO[k].isspace()))]\n",
    "\n",
    "    }\n",
    "    headers = {\n",
    "    # Request headers\n",
    "    'Content-Type': 'text/json',\n",
    "    'Ocp-Apim-Subscription-Key': API_KEY,\n",
    "    }\n",
    "\n",
    "    params = urllib.parse.urlencode({\n",
    "    })\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn.request(\"POST\", \"/text/analytics/v2.0/sentiment?%s\" % params, str(body), headers)\n",
    "        data = response.read()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n",
    "    return data\n",
    "    \n",
    "datas={character:get_data(interventions[character]) for character in characters}\n",
    "print(datas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import codecs\n",
    "import urllib.request\n",
    "API_KEY=\"0ce77ac4203a40569f40a3a37525ece4\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "# Request headers\n",
    "'Content-Type': 'text/json',\n",
    "'Ocp-Apim-Subscription-Key': API_KEY,\n",
    "}\n",
    "params = urllib.parse.urlencode({\n",
    "})\n",
    "conn = http.client.HTTPSConnection('westus.api.cognitive.microsoft.com')\n",
    "body={\n",
    "  \"documents\": [\n",
    "    {\n",
    "      \"id\": \"id\",\n",
    "      \"text\": \"phrase test\"\n",
    "    } ]\n",
    "\n",
    "}\n",
    "conn.request(\"POST\",\"/text/analytics/v2.0/sentiment?%s\", str(body),headers)\n",
    "response = conn.getresponse()\n",
    "print(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's get the list of the scores out of this\n",
    "def read_data(data):\n",
    "    scores=[]\n",
    "    data=(ast.literal_eval(str(data)[2:(len(data)+2)]))\n",
    "    for sentence in data[\"documents\"]:\n",
    "        scores.append(sentence[\"score\"])\n",
    "    return scores\n",
    "\n",
    "scores={character:read_data(datas[character]) for character in characters}\n",
    "print(\"mean scores per character\")\n",
    "for character in characters:\n",
    "    print(character,len(scores[character]),np.mean(scores[character]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>The empire strikes back</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.imsdb.com/scripts/Star-Wars-The-Empire-Strikes-Back.html\"\n",
    "u = urllib.request.urlopen(url, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8')\n",
    "text = f.read()\n",
    "script=text.split(\"scrtext\")[1]\n",
    "script=script.replace(\"\\n\",\"\").split(\"<b>\")\n",
    "characters=[\"THREEPIO\",\"LUKE\",\"VADER\",\"HAN\",\"LEIA\"]\n",
    "interventions=sort_by_characters(characters,script)\n",
    "datas={character : get_data(interventions[character]) for character in characters}\n",
    "scores={character : [k for k in read_data(datas[character]) if k!=0.5] for character in characters}\n",
    "print(\"mean scores per character\")\n",
    "for character in characters:\n",
    "    print(character,len(scores[character]),np.mean(scores[character]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The force awakens</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.imsdb.com/scripts/Star-Wars-The-Force-Awakens.html\"\n",
    "u = urllib.request.urlopen(url, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8')\n",
    "text = f.read()\n",
    "script=text.split(\"scrtext\")[1]\n",
    "script=script.replace(\"\\n\",\"\").split(\"<b>\")\n",
    "characters=[\"FINN\",\"REY\",\"HAN\",\"KYLO REN\"]\n",
    "interventions=sort_by_characters(characters,script)\n",
    "datas={character : get_data(interventions[character]) for character in characters}\n",
    "scores={character : [k for k in read_data(datas[character]) if k!=0.5] for character in characters}\n",
    "print(\"mean scores per character\")\n",
    "for character in characters:\n",
    "    print(character,len(scores[character]),np.mean(scores[character]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see, Finn, rey, and especially Kylo Ren are not that happy to be there. I'd argue that the tone of this movie is darker than the original trilogy for the part they are involved in, so I'm not that surprised.\n",
    "\n",
    "<b> Apocalypse now </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.imsdb.com/scripts/Apocalypse-Now.html\"\n",
    "u = urllib.request.urlopen(url, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8',errors='ignore')\n",
    "text = f.read()\n",
    "script=text.split(\"scrtext\")[1]\n",
    "script=script.replace(\"\\n\",\"\").split(\"<b>\")\n",
    "characters=[\"WILLARD\",\"KILGORE\",\"GASTON\",\"CHIEF\",\"LANCE\",\"KURTZ\"]\n",
    "interventions=sort_by_characters(characters,script)\n",
    "datas={character : get_data(interventions[character]) for character in characters}\n",
    "scores={character : [k for k in read_data(datas[character]) if k!=0.5] for character in characters}\n",
    "print(\"mean scores per character\")\n",
    "for character in characters:\n",
    "    print(character,len(scores[character]),np.mean(scores[character]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now test the key phrase extraction option, just to test it and check the kind of words coming out of it. Roughly, it seems to be about war. I believe more could be with this, but I lack inspiration here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=get_data(interventions[\"GASTON\"],param=\"KeyPhrases\")\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the emotions of Willard with the evolution of the movie. We do smooth a little bit the shape of the data so to have a broad impression of the emotion at a given time.\n",
    "Here we can see a few cycles, corresponding to the different steps of Willard journey to hell. It gets darker with time, untill Willard embraces his madness (and then it seems fine?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[np.mean([j for j in scores[\"WILLARD\"][max(0,k-10):min(len(scores[\"WILLARD\"])-1,k+10)]]) for k in range(len(scores[\"WILLARD\"]))]\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> V for Vendetta </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://www.imsdb.com/scripts/V-for-Vendetta.html\"\n",
    "u = urllib.request.urlopen(url, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8',errors='ignore')\n",
    "text = f.read()\n",
    "script=text.split(\"scrtext\")[1]\n",
    "script=script.replace(\"\\n\",\"\").split(\"<b>\")\n",
    "characters=[\"EVEY\",\"V\",\"PROTHERO\",\"LEADER\"]\n",
    "interventions=sort_by_characters(characters,script)\n",
    "datas={character : get_data(interventions[character]) for character in characters}\n",
    "scores={character : [k for k in read_data(datas[character]) if k!=0.5] for character in characters}\n",
    "print(\"mean scores per character\")\n",
    "for character in characters:\n",
    "    print(character,len(scores[character]),np.mean(scores[character]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2=[np.mean([j for j in scores[\"EVEY\"][max(0,k-10):min(len(scores[\"EVEY\"])-1,k+10)]]) for k in range(len(scores[\"EVEY\"]))]\n",
    "plt.plot(scores2)\n",
    "plt.xlabel('Evey sentiment through the movie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2=[np.mean([j for j in scores[\"LEADER\"][max(0,k-10):min(len(scores[\"LEADER\"])-1,k+10)]]) for k in range(len(scores[\"LEADER\"]))]\n",
    "plt.plot(scores2)\n",
    "plt.xlabel('leader sentiment through the movie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Above, the evolution of the emotions of Evey and the leader. We can pinpoint that both are symetrical, reflecting opposing evolutions during the movie. The time Evey spends in prison is specially obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Conclusion </b>\n",
    "\n",
    "As we've seen, getting a single emotion, from 1 to 0, out of a sentence, is not obvious, and the cognitive service will often fail at it. \n",
    "However, when we look at the broader picture, we can see that the sentiment indicator given by the API is able to reflect the plot of a movie, and to give insight about what a character is going through.\n",
    "\n",
    "We can expand this work by saying that the service will be specially relevant to estimate broad satisfaction, but might fail at detecting one specific emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
